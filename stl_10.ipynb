{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2GzoN7S8KPt"
      },
      "source": [
        "# Chargement des données STL10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6OVXs-8KP3"
      },
      "source": [
        " STL10 contient 5000 images d'entraînement et 8000 images de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KsFDu7Uj8KP5"
      },
      "outputs": [],
      "source": [
        "# path_to_data = \"./STL10_9696\"\n",
        "path_to_data = \"./STL10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ep6uMdVn8KP9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Transformations basiques sans augmentation\n",
        "transform_base = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Redimensionnement pour le modèle\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalisation\n",
        "])\n",
        "\n",
        "# Chargement du dataset STL10\n",
        "# Les images STL10 sont de dimension 96x96.\n",
        "# trainset = datasets.STL10(root=path_to_data, split='train', download=True, transform=transform_base)\n",
        "# testset = datasets.STL10(root=path_to_data, split='test', download=True, transform=transform_base)\n",
        "\n",
        "# print(f\"Dataset STL10 chargé: {len(trainset)} images d'entraînement, {len(testset)} images de test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0G5snIUB9eX",
        "outputId": "283bf446-8566-480f-86b2-f9d164145a33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.STL10(root=\"drive/MyDrive/SDD/data_augmentation/STL10\", split='train', download=False, transform=transform_base)\n",
        "testset = datasets.STL10(root=\"drive/MyDrive/SDD/data_augmentation/STL10\", split='test', download=False, transform=transform_base)"
      ],
      "metadata": {
        "id": "8EHam250B-kG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(testset, batch_size=128, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "Wr4u6J40NtE2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset = trainset_\n",
        "# testset = testset_"
      ],
      "metadata": {
        "id": "VR-uVvW0GlPV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9M1O1wUT8KQB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "ZWu6fCux8KQD",
        "outputId": "02a2cdfa-838e-47e5-c415-efd68b13777a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.75686276..0.92156863].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7af4a0575290>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plt.imshow(trainset[0][0])\n",
        "plt.imshow(np.transpose(trainset[4][0],(1,2,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjwDvzLr8KQF"
      },
      "source": [
        "# Définition de l'agent LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwmKLP9P8KQH"
      },
      "source": [
        "Ce LSTM prend en entrée un vecteur aléatoire et génère une politique d'augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5rt7ui8KQI"
      },
      "source": [
        "Ce LSTM génère une politique d'augmentation sous forme de 5 nombres entre 0 et 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqLaN5T88KQJ",
        "outputId": "902e472b-9839-4436-d518-c5babd17f40c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0dJVkMPv8KQK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class AutoAugmentLSTM(nn.Module):\n",
        "    def __init__(self, input_size=10, hidden_size=128, num_layers=2, output_size=5):\n",
        "        super(AutoAugmentLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # 5 valeurs pour 5 types d'augmentation\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])  # Dernière sortie de la séquence\n",
        "        return torch.sigmoid(out)  # Convertir en probabilités entre 0 et 1\n",
        "\n",
        "lstm = AutoAugmentLSTM().to(device)\n",
        "# lstm = AutoAugmentLSTM().cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EmYYDdl8KQL"
      },
      "source": [
        "# Génération des Politiques d’Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcaORXBJ8KQM"
      },
      "source": [
        "On convertit la sortie du LSTM en transformations dynamiques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7XgKPAQ8KQM"
      },
      "source": [
        "Seules certaines transformations sont appliquées selon la politique générée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ObRZf1lR8KQN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def apply_augmentations(image,\n",
        "                        policy,\n",
        "                        replace : bool # this argument is used to specify if the data should be replaced by the augmented data or enriched.\n",
        "                        ):\n",
        "    augmentations = [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "        transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "        transforms.GaussianBlur(kernel_size=3)\n",
        "    ]\n",
        "    image_aug = image\n",
        "\n",
        "    for i, aug in enumerate(augmentations):\n",
        "        if policy[i] > 0.5:  # Seuil pour activer une transformation\n",
        "            image_aug = aug(image)\n",
        "    if replace :\n",
        "        return image_aug\n",
        "    else :\n",
        "        return image, image_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmZuK9V_8KQO"
      },
      "source": [
        "# Modèle Proxy pour Tester les Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2NNMXI8KQO"
      },
      "source": [
        "On entraîne un CNN léger (ResNet18) sur les données augmentées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Ef3yQs8KQP"
      },
      "source": [
        "Ce modèle proxy nous permet de tester si une politique d’augmentation améliore l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "no08wKwo_onP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQDS2azJ8KQP"
      },
      "source": [
        "### Un proxy simplissime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N687qR48KQQ"
      },
      "source": [
        "Performances :\n",
        "\n",
        "    RUN_0 :\n",
        "        images 32x32\n",
        "        batch_size=64\n",
        "        20%|██        | 1/5 [00:51<03:27, 51.93s/it] Epoch [1/5], Loss: 1.7010\n",
        "        num_worker=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AWrwtPhM8KQQ"
      },
      "outputs": [],
      "source": [
        "input_size = 32*32  # images are 32x32 pixels\n",
        "output_size = 10  # there are 10 classes\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # print(x.shape)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "proxy_model=SimpleCNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Définition du modèle\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Première couche de convolution : entrée 3 canaux (RGB), sortie 32 filtres 3x3\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        # MaxPooling 2x2 pour réduire la taille de l'image\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Couche entièrement connectée :\n",
        "        # L'entrée doit correspondre à la taille après convolutions + pooling\n",
        "        self.fc1 = nn.Linear(in_features=64 * 8 * 8, out_features=128)  # 64 cartes de 8x8\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=10)  # 10 classes\n",
        "        # Placeholder pour fc1 (on ajustera dynamiquement)\n",
        "        # self.fc1 = nn.Linear(1, 128)  # Placebo, on corrigera après\n",
        "        # self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Convolution + ReLU + MaxPooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Convolution + ReLU + MaxPooling\n",
        "        # print(f\"Taille après convolutions et pooling: {x.shape}\")\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Mise à plat (Flatten)\n",
        "        # print(f\"Taille après flatten: {x.shape}\")\n",
        "        x = F.relu(self.fc1(x))  # Couche entièrement connectée + ReLU\n",
        "        x = self.fc2(x)  # Dernière couche (sortie brute, non normalisée)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Vérification du modèle\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "proxy_model=SimpleCNN().to(device)\n",
        "print(proxy_model)  # Affichage de la structure du modèle\n"
      ],
      "metadata": {
        "id": "DvR6F_V8ZOzE",
        "outputId": "c61dc03c-e4c6-4dfc-aa09-77002f6a634d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(proxy_model)"
      ],
      "metadata": {
        "id": "0JOhYYeGUfKI",
        "outputId": "117c3781-21c9-41b3-998a-e276746b73b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6rLBcp18KQR"
      },
      "source": [
        "### Un proxy moins simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "2nSLmVD-8KQS"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "proxy_model = models.resnet18(num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kZgfzRjZ8KQT"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(proxy_model.parameters(), lr=0.001)\n",
        "\n",
        "def train_proxy_model(train_loader, model, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_proxy_model(model, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad() :\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for images, labels in test_loader :\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss /len(test_loader)\n",
        "    return accuracy, avg_loss"
      ],
      "metadata": {
        "id": "r6zNgYKTNadZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K55et9C38KQU"
      },
      "source": [
        "# Boucle de Recherche pour Optimiser l’AutoAugment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJGV4_RY8KQU"
      },
      "source": [
        "On entraîne le LSTM en mettant à jour ses poids en fonction de l'amélioration des performances du modèle proxy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W7Ry1U38KQU"
      },
      "source": [
        "Perfromances :\n",
        "\n",
        "    RUN_0 :\n",
        "        images 96x96\n",
        "        batch_size=128\n",
        "        60%|██████    | 3/5 [02:47<01:52, 56.39s/it]Epoch [3/5], Loss: 1.1865\n",
        "        num_worker=4\n",
        "\n",
        "    RUN_1 :\n",
        "        images 32x32\n",
        "        batch_size=128\n",
        "        num_worker=4\n",
        "        40%|████      | 2/5 [01:55<02:53, 57.88s/it]\n",
        "\n",
        "    RUN_2 :\n",
        "        images 32x32\n",
        "        batch_size=64\n",
        "        num_worker=4\n",
        "        40%|████      | 2/5 [02:05<03:07, 62.54s/it]\n",
        "\n",
        "    RUN_3 :\n",
        "        images 32x32\n",
        "        batch_size=64\n",
        "        num_worker=8\n",
        "        20%|██        | 1/5 [01:00<04:00, 60.17s/it] Epoch [1/5], Loss: 1.1175\n",
        "\n",
        "    RUN_4 :\n",
        "        images 32x32\n",
        "        batch_size=64\n",
        "        num_worker=8\n",
        "        20%|██        | 1/5 [01:01<04:06, 61.54s/it] Epoch [1/5], Loss: 0.9135"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "0298q0wO8KQV",
        "outputId": "a92b8c7e-2a58-4d17-c526-efc5c6aaae03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            " 20%|██        | 1/5 [00:03<00:15,  3.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 2.5817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:09<00:14,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Loss: 2.5868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:13<00:09,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Loss: 2.5834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:17<00:04,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Loss: 2.5871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:21<00:00,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Loss: 2.5815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1, 5])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Reward: 0.1072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:04<00:16,  4.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 2.5882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:09<00:15,  5.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Loss: 2.5872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:13<00:09,  4.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Loss: 2.5752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:17<00:04,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Loss: 2.5724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:22<00:00,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Loss: 2.5807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Reward: 0.1069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:05<00:21,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 2.5759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:09<00:14,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Loss: 2.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:13<00:08,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Loss: 2.5822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:17<00:04,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Loss: 2.5693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:23<00:00,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Loss: 2.5851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2, Reward: 0.1049\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-57b87aa88e0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Appliquer la politique générée\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     trainset_augmented = datasets.STL10(root=path_to_data, split='train', download=False,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                         transform=transforms.Compose([\n\u001b[1;32m     13\u001b[0m                                             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, folds, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found or corrupted. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer_lstm = optim.Adam(lstm.parameters(), lr=0.001)\n",
        "loss_lstm = nn.MSELoss()  # Comparaison avec l'amélioration attendue\n",
        "\n",
        "baseline_accuracy = 0.0\n",
        "\n",
        "for iteration in range(100):  # Nombre d'itérations de recherche\n",
        "    lstm_input = torch.randn(1, 10, 10).to(device)  # Entrée aléatoire\n",
        "    policy = lstm(lstm_input).detach().cpu().numpy()[0]  # Convertir en numpy\n",
        "\n",
        "    # Appliquer la politique générée\n",
        "    trainset_augmented = datasets.STL10(root=path_to_data, split='train', download=False,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Resize((32, 32)),\n",
        "                                            transforms.Normalize((0.5,), (0.5,)),\n",
        "                                            lambda img: apply_augmentations(img, policy, replace=True)])\n",
        "                                        # transform = transforms.ToTensor()\n",
        "                                        )\n",
        "\n",
        "    train_loader_aug = DataLoader(trainset_augmented, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "    # Entraîner le modèle proxy avec la politique d'augmentation actuelle\n",
        "    train_proxy_model(train_loader_aug, proxy_model, criterion, optimizer)\n",
        "\n",
        "    # Évaluer la précision après augmentation\n",
        "    accuracy_after, avg_loss = evaluate_proxy_model(proxy_model, test_loader)\n",
        "\n",
        "    # Calculer la récompense et mettre à jour le LSTM\n",
        "    reward = accuracy_after - baseline_accuracy\n",
        "    loss = loss_lstm(torch.tensor([reward], dtype=torch.float32).to(device), lstm(lstm_input))\n",
        "    optimizer_lstm.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_lstm.step()\n",
        "\n",
        "    print(f\"Iteration {iteration}, Reward: {reward:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UI_k4C48KQW"
      },
      "source": [
        "# Application de la Meilleure Politique Trouvée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngHcG1K8KQX"
      },
      "source": [
        "Une fois la meilleure politique identifiée, on applique la meilleure politique trouvée et on entraîne un modèle final performant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh7X9fAT8KQX"
      },
      "outputs": [],
      "source": [
        "best_policy = find_best_policy(lstm)  # Fonction qui extrait la meilleure politique\n",
        "print(f\"Meilleure politique trouvée : {best_policy}\")\n",
        "\n",
        "# Appliquer aux données finales\n",
        "transform_final = lambda img: apply_augmentations(img, best_policy)\n",
        "trainset_final = datasets.STL10(root=\"./data\", split='train', download=True, transform=transform_final)\n",
        "train_loader_final = DataLoader(trainset_final, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "# Entraîner le modèle final (ex: WideResNet)\n",
        "final_model = WideResNet(depth=28, width=10, num_classes=10).cuda()\n",
        "optimizer_final = optim.SGD(final_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "train_final_model(train_loader_final, final_model, criterion, optimizer_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XrIlg8_8KQX"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ZcNRcv8KQX"
      },
      "outputs": [],
      "source": [
        "# from simple_cnn import SimpleCNN\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "# # Initialisation du modèle\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = SimpleCNN().to(device)\n",
        "\n",
        "# # Fonction de perte et optimiseur\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# # Entraînement du modèle sur les données brutes\n",
        "# for epoch in range(10):  # Petit entraînement pour test\n",
        "#     for images, labels in train_loader:\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "# print(\"✅ Modèle entraîné sur données brutes !\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AhdJpKy8KQY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}